{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "academic-ethnic",
   "metadata": {},
   "source": [
    "# Using Tf to form a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "second-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"data/test.csv\")\n",
    "train_dataset = pd.read_csv(\"data/train.csv\")\n",
    "columns = [\"img_paths\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "assured-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.sample(frac=1)\n",
    "train_dataset = train_dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "engaging-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "# train_dataset.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "test_dataset.reset_index(inplace=True, drop=True)\n",
    "train_dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "developing-sessions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"data/data/test/0/103277.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "persistent-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def load_dataset(df):   \n",
    "    ##############Getting the image Paths#################\n",
    "#     df = pd.read_csv(path)\n",
    "    img_paths = df.img_paths\n",
    "    labels = df.labels\n",
    "    ######################################################\n",
    "    ##############Reading the images Grayscale############\n",
    "    imgs = []\n",
    "    for img in img_paths:\n",
    "#         start = time.time()\n",
    "        temp = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "        imgs.append(temp)\n",
    "#         end = time.time()\n",
    "#         print(end-start)\n",
    "        \n",
    "    ######################################################\n",
    "    #######Converting to numpy array for faster calculations#####\n",
    "    labels = np.asarray(labels).astype('uint8')\n",
    "    imgs = np.asarray(imgs)\n",
    "    return labels, imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "offshore-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, x_train = load_dataset(train_dataset)\n",
    "y_test, x_test = load_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "comparable-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filenames = [\"dump/x_train.txt\",\"dump/x_test.txt\", \"dump/y_train.txt\",\"dump/y_test.txt\"]\n",
    "listings = [x_train, x_test, y_train, y_test]\n",
    "for listing, filename in zip(listings, filenames):\n",
    "    f = open(filename, 'wb')\n",
    "    pickle.dump(listing, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-samoa",
   "metadata": {},
   "source": [
    "# Load Data (Alternative starting point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broadband-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "endangered-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filenames = [\"dump/x_train.txt\",\"dump/x_test.txt\", \"dump/y_train.txt\",\"dump/y_test.txt\"]\n",
    "f = open(filenames[0], 'rb')\n",
    "x_train  = pickle.load(f)\n",
    "f = open(filenames[1], 'rb')\n",
    "x_test = pickle.load(f)\n",
    "f = open(filenames[2], 'rb')\n",
    "y_train = pickle.load(f)\n",
    "f = open(filenames[3], 'rb')\n",
    "y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mental-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(data):\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False) # disable sparse return type\n",
    "    \n",
    "    # reshape the array\n",
    "    data = data.reshape(len(data), 1)\n",
    "    data = onehot_encoder.fit_transform(data) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assured-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = oneHotEncode(y_test)\n",
    "y_train = oneHotEncode(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "welsh-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 32, 32, 1)\n",
    "x_test = x_test.reshape(-1, 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "classical-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test/255\n",
    "x_train = x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "parallel-carroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-chuck",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "representative-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_height, img_width, img_ch, num_classes):\n",
    "    model = Sequential([\n",
    "#         layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, img_ch)),\n",
    "        layers.Conv2D(16, 3,input_shape=(img_height, img_width, img_ch), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes)        \n",
    "    ])\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "charged-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(img_height, img_width, img_ch, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(img_height, img_width, img_ch)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "knowing-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(32,32,1,46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "center-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model2(32,32,1,46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "similar-petite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 46)                5934      \n",
      "=================================================================\n",
      "Total params: 1,630,510\n",
      "Trainable params: 1,630,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bigger-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 71s 91ms/step - loss: 0.0073 - accuracy: 0.7587 - val_loss: 0.0038 - val_accuracy: 0.8842\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 71s 90ms/step - loss: 0.0062 - accuracy: 0.7968 - val_loss: 0.0032 - val_accuracy: 0.9005\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 74s 95ms/step - loss: 0.0056 - accuracy: 0.8163 - val_loss: 0.0028 - val_accuracy: 0.9137\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 75s 96ms/step - loss: 0.0051 - accuracy: 0.8347 - val_loss: 0.0025 - val_accuracy: 0.9222\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 77s 99ms/step - loss: 0.0047 - accuracy: 0.8473 - val_loss: 0.0023 - val_accuracy: 0.9288\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"Conv2d.h5\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=100, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beginning-mongolia",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-921486b32fea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# plt.imshow(y_train[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "# plt.imshow(y_train[0])\n",
    "np.argmax(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-spencer",
   "metadata": {},
   "source": [
    "# Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sudden-celebration",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0d47951749e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv2/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2838\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2839\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2840\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2841\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/.virtualenvs/cv2/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv2/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv2/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (5,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAHWCAYAAABaAET5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPWElEQVR4nO3bf6jdd33H8ee7zTpZV+swV5AmsZWl06wO2l26DmF22I20g+QPN0mgbI7SoLMyUAYdHZ3Uv9yYAyGbC6xUBVujf4wLplTmKgUx2ltaq0mpXGO3psoaa+0/pb/Ye3+c43Z6TXq/9+Tck9sXzwcEzvd7Pvd73pzkeb/nfu831d1IynTeuR5A0sYxcCmYgUvBDFwKZuBSMAOXgq0ZeFXdWVVPV9X3zvB8VdWnq2qlqh6tqqtmP6akaQw5g98F7H6N568Hdo7/HAD++ezHkjQLawbe3Q8AP32NJXuBz/XIUeBNVfXWWQ0oaXqz+Bn8EuDJie2T432SzrEt83yxqjrA6GM8F1544W+/4x3vmOfLS69LDz300E+6e2Gar51F4E8B2ye2t433/YLuPgQcAlhcXOzl5eUZvLyUrar+c9qvncVH9CXgT8dX068BnuvuH8/guJLO0ppn8Kq6G7gW2FpVJ4G/BX4JoLs/AxwBbgBWgOeBP9+oYSWtz5qBd/f+NZ5v4MMzm0jSzHgnmxTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCjYo8KraXVWPV9VKVd16mud3VNX9VfVwVT1aVTfMflRJ67Vm4FV1PnAQuB7YBeyvql2rlv0NcLi7rwT2Af8060Elrd+QM/jVwEp3n+jul4B7gL2r1jTwxvHji4EfzW5ESdPaMmDNJcCTE9sngd9ZtebjwFer6iPAhcB1M5lO0lmZ1UW2/cBd3b0NuAH4fFX9wrGr6kBVLVfV8qlTp2b00pLOZEjgTwHbJ7a3jfdNugk4DNDd3wTeAGxdfaDuPtTdi929uLCwMN3EkgYbEviDwM6quqyqLmB0EW1p1Zr/At4LUFXvZBS4p2jpHFsz8O5+BbgFuA94jNHV8mNVdUdV7Rkv+xhwc1V9B7gb+EB390YNLWmYIRfZ6O4jwJFV+26feHwcePdsR5N0tryTTQpm4FIwA5eCGbgUzMClYAYuBTNwKZiBS8EMXApm4FIwA5eCGbgUzMClYAYuBTNwKZiBS8EMXApm4FIwA5eCGbgUzMClYAYuBTNwKZiBS8EMXApm4FIwA5eCGbgUzMClYAYuBTNwKZiBS8EMXApm4FIwA5eCGbgUzMClYAYuBTNwKZiBS8EMXApm4FIwA5eCGbgUzMClYAYuBTNwKZiBS8EMXApm4FIwA5eCGbgUzMClYAYuBTNwKZiBS8EMXApm4FIwA5eCGbgUzMClYAYuBTNwKZiBS8EMXApm4FIwA5eCGbgUzMClYAYuBTNwKZiBS8EMXApm4FIwA5eCGbgUzMClYAYuBRsUeFXtrqrHq2qlqm49w5r3V9XxqjpWVV+Y7ZiSprFlrQVVdT5wEPgD4CTwYFUtdffxiTU7gb8G3t3dz1bVWzZqYEnDDTmDXw2sdPeJ7n4JuAfYu2rNzcDB7n4WoLufnu2YkqYxJPBLgCcntk+O9026HLi8qr5RVUeravesBpQ0vTU/oq/jODuBa4FtwANV9a7u/tnkoqo6ABwA2LFjx4xeWtKZDDmDPwVsn9jeNt436SSw1N0vd/cPge8zCv5VuvtQdy929+LCwsK0M0saaEjgDwI7q+qyqroA2AcsrVrzb4zO3lTVVkYf2U/MbkxJ01gz8O5+BbgFuA94DDjc3ceq6o6q2jNedh/wTFUdB+4H/qq7n9mooSUNU919Tl54cXGxl5eXz8lrS68nVfVQdy9O87XeySYFM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVgBi4FM3ApmIFLwQxcCmbgUjADl4INCryqdlfV41W1UlW3vsa691VVV9Xi7EaUNK01A6+q84GDwPXALmB/Ve06zbqLgL8EvjXrISVNZ8gZ/GpgpbtPdPdLwD3A3tOs+wTwSeCFGc4n6SwMCfwS4MmJ7ZPjff+nqq4Ctnf3V2Y4m6SzdNYX2arqPOBTwMcGrD1QVctVtXzq1KmzfWlJaxgS+FPA9ontbeN9P3cRcAXw9ap6ArgGWDrdhbbuPtTdi929uLCwMP3UkgYZEviDwM6quqyqLgD2AUs/f7K7n+vurd19aXdfChwF9nT38oZMLGmwNQPv7leAW4D7gMeAw919rKruqKo9Gz2gpOltGbKou48AR1btu/0Ma689+7EkzYJ3sknBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWCDAq+q3VX1eFWtVNWtp3n+o1V1vKoeraqvVdXbZj+qpPVaM/CqOh84CFwP7AL2V9WuVcseBha7+7eALwN/N+tBJa3fkDP41cBKd5/o7peAe4C9kwu6+/7ufn68eRTYNtsxJU1jSOCXAE9ObJ8c7zuTm4B7z2YoSbOxZZYHq6obgUXgPWd4/gBwAGDHjh2zfGlJpzHkDP4UsH1ie9t436tU1XXAbcCe7n7xdAfq7kPdvdjdiwsLC9PMK2kdhgT+ILCzqi6rqguAfcDS5IKquhL4F0ZxPz37MSVNY83Au/sV4BbgPuAx4HB3H6uqO6pqz3jZ3wO/Cnypqh6pqqUzHE7SHA36Gby7jwBHVu27feLxdTOeS9IMeCebFMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKZuBSMAOXghm4FMzApWAGLgUzcCmYgUvBDFwKNijwqtpdVY9X1UpV3Xqa53+5qr44fv5bVXXpzCeVtG5rBl5V5wMHgeuBXcD+qtq1atlNwLPd/evAPwKfnPWgktZvyBn8amClu09090vAPcDeVWv2Ap8dP/4y8N6qqtmNKWkaQwK/BHhyYvvkeN9p13T3K8BzwJtnMaCk6W2Z54tV1QHgwHjzxar63jxffwpbgZ+c6yFew2afDzb/jJt9PoDfmPYLhwT+FLB9YnvbeN/p1pysqi3AxcAzqw/U3YeAQwBVtdzdi9MMPS+bfcbNPh9s/hk3+3wwmnHarx3yEf1BYGdVXVZVFwD7gKVVa5aAPxs//mPgP7q7px1K0myseQbv7leq6hbgPuB84M7uPlZVdwDL3b0E/Cvw+apaAX7K6JuApHNs0M/g3X0EOLJq3+0Tj18A/mSdr31onevPhc0+42afDzb/jJt9PjiLGctP0lIub1WVgm144Jv9NtcB8320qo5X1aNV9bWqets85xsy48S691VVV9XcrwoPmbGq3j9+L49V1Rc203xVtaOq7q+qh8d/1zfMeb47q+rpM/3quEY+PZ7/0aq6atCBu3vD/jC6KPcD4O3ABcB3gF2r1vwF8Jnx433AFzdypinm+33gV8aPPzTP+YbOOF53EfAAcBRY3GwzAjuBh4FfG2+/ZZPNdwj40PjxLuCJOb+HvwdcBXzvDM/fANwLFHAN8K0hx93oM/hmv811zfm6+/7ufn68eZTRfQDzNOQ9BPgEo/8D8MI8hxsbMuPNwMHufhagu5/eZPM18Mbx44uBH81xPrr7AUa/gTqTvcDneuQo8Kaqeutax93owDf7ba5D5pt0E6PvovO05ozjj2vbu/sr8xxswpD38XLg8qr6RlUdrardc5tu2HwfB26sqpOMfmP0kfmMNth6/60Cc75V9fWsqm4EFoH3nOtZJlXVecCngA+c41HWsoXRx/RrGX0KeqCq3tXdPzuXQ03YD9zV3f9QVb/L6L6OK7r7f871YGdjo8/g67nNlde6zXWDDJmPqroOuA3Y090vzmm2n1trxouAK4CvV9UTjH4+W5rzhbYh7+NJYKm7X+7uHwLfZxT8ZpnvJuAwQHd/E3gDo/vUN4tB/1Z/wQZfONgCnAAu4/8vbvzmqjUf5tUX2Q7P8cLGkPmuZHSBZuc8L7qsZ8ZV67/O/C+yDXkfdwOfHT/eyujj5ps30Xz3Ah8YP34no5/Ba87v46Wc+SLbH/Hqi2zfHnTMOQx9A6Pv1j8Abhvvu4PR2RBG3ym/BKwA3wbePuc3da35/h34b+CR8Z+lec43ZMZVa+ce+MD3sRj9KHEc+C6wb5PNtwv4xjj+R4A/nPN8dwM/Bl5m9GnnJuCDwAcn3r+D4/m/O/Tv2DvZpGDeySYFM3ApmIFLwQxcCmbgUjADl4IZuBTMwKVg/wtqRNzGGFxpeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(100)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-member",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "earlier-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/Conv2d.h5\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-highway",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "motivated-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"models/Conv2d.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "antique-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "\n",
    "tfjs.converters.save_keras_model(model, \"model_js\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "graphic-terrace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.002279395703226328\n",
      "Test accuracy: 0.9288405776023865\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('cv2')",
   "language": "python",
   "name": "python38564bitcv26904d6122b074f8eb176bd13278a6f95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
